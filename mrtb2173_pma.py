# -*- coding: utf-8 -*-
"""MRTB2173_PMA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gx08Q9pQaj_1ezLUE9OqfUiTQJU6jPsj
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix
from imblearn.over_sampling import SMOTE
import joblib
import streamlit as st

def load_data(uploaded_files):
    """Load and merge uploaded datasets."""
    try:
        employee_data = pd.read_csv(uploaded_files["employee_data"])
        engagement_data = pd.read_csv(uploaded_files["engagement_data"])
        training_data = pd.read_csv(uploaded_files["training_data"])

        # Merge datasets
        df = employee_data.merge(engagement_data, left_on='EmpID', right_on='Employee ID', how='left')
        df = df.merge(training_data, left_on='EmpID', right_on='Employee ID', how='left')

        # Standardize column names
        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')

        return df
    except Exception as e:
        st.error("Error loading data: " + str(e))
        return None

def preprocess_data(df):
    """Preprocess the data for analysis and modeling."""
    # Handle missing values for numeric columns by filling with median
    numeric_cols = ['engagement_score', 'satisfaction_score', 'work-life_balance_score', 'training_cost']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = df[col].fillna(df[col].median())

    # Drop irrelevant or unnamed columns
    df.drop(columns=['unnamed:_0'], errors='ignore', inplace=True)

    # Convert date columns to datetime
    date_cols = ['startdate', 'exitdate']
    for col in date_cols:
        df[col] = pd.to_datetime(df[col], format='%d-%b-%y', errors='coerce')

    # Handle the dob column separately for dd/mm/yyyy format
    if 'dob' in df.columns:
        df['dob'] = df['dob'].str.replace(r'[^\d]', '', regex=True)
        df['dob'] = pd.to_datetime(df['dob'], format='%d%m%Y', errors='coerce')

    # Calculate Age and Employment Duration
    if 'dob' in df.columns:
        df['age'] = 2025 - df['dob'].dt.year
    if 'exitdate' in df.columns and 'startdate' in df.columns:
        df['exitdate'].fillna(pd.Timestamp.today(), inplace=True)
        df['employment_duration'] = (df['exitdate'] - df['startdate']).dt.days

    # Standardize and encode categorical columns
    label_encoder = LabelEncoder()
    if 'employeestatus' in df.columns:
        status_mapping = {'Active': 1, 'Future Start': 2, 'Voluntarily Terminated': 3, 'Leave of Absence': 4, 'Terminated for Cause': 5}
        df['employeestatus'] = df['employeestatus'].map(status_mapping)
    if 'performance_score' in df.columns:
        performance_mapping = {'Fully Meets': 1, 'Exceeds': 2, 'Needs Improvement': 3, 'PIP': 4}
        df['performance_score'] = df['performance_score'].map(performance_mapping)

    # Create the target variable 'LeftCompany'
    df['LeftCompany'] = df['employeestatus'].apply(lambda x: 1 if x in [3, 4, 5] else 0)

    # Drop unique columns
    columns_to_drop = ['firstname', 'lastname', 'startdate', 'exitdate', 'title', 'supervisor', 'ademail', 'businessunit', 'terminationdescription', 'dob', 'jobfunctiondescription',
                      'locationcode', 'employee_id_x', 'survey_date', 'employee_id_y', 'training_date', 'location', 'trainer']
    df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)

    return df

def perform_eda(df):
    """Perform exploratory data analysis and visualize results."""

    # General overview
    st.write("### Dataset Statistics")
    st.dataframe(df.describe())

    # Visualizing employee demographics
    st.write("### Gender Distribution")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x='gendercode', data=df, palette='coolwarm', ax=ax)
    st.pyplot(fig)

    # Group the data into age ranges
    age_bins = [18, 25, 35, 45, 55, 65, 100]
    age_labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']
    df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=False)

    # Plot the age distribution by age group
    st.write("### Age Distribution")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x='age_group', data=df, palette='coolwarm', ax=ax)
    st.pyplot(fig)

    st.write("### Race Distribution")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x='racedesc', data=df, palette='coolwarm', ax=ax)
    st.pyplot(fig)

    st.write("### Marital Status Distribution")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x='maritaldesc', data=df, palette='coolwarm', ax=ax)
    st.pyplot(fig)

    # Visualizing departmental trends
    st.write("### Department Distribution by Payzone")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x='departmenttype', data=df, hue='payzone', palette='Set2', ax=ax)
    plt.xticks(rotation=45)
    st.pyplot(fig)

    # Mapping employee status labels
    status_reverse_mapping = {1: 'Active', 2: 'Future Start', 3: 'Voluntarily Terminated', 4: 'Leave of Absence', 5: 'Terminated for Cause'}
    df['EmployeeStatusLabel'] = df['employeestatus'].map(status_reverse_mapping)

    st.write("### Employee Status Distribution by Payzone")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x='EmployeeStatusLabel', data=df, hue='payzone', palette='Set2', ax=ax)
    plt.xticks(rotation=45)
    st.pyplot(fig)

    # Visualizing trends in engagement and turnover
    st.write("### Performance Score Distribution by Payzone")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.histplot(df, x='performance_score', hue='payzone', kde=True, palette='Set2', ax=ax)
    st.pyplot(fig)

    st.write("### Engagement Score Distribution by Payzone")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.histplot(df, x='engagement_score', hue='payzone', kde=True, palette='Set2', ax=ax)
    st.pyplot(fig)

    st.write("### Satisfaction Score Distribution by Payzone")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.histplot(df, x='satisfaction_score', hue='payzone', kde=True, palette='Set2', ax=ax)
    st.pyplot(fig)

    st.write("### Correlation Heatmap")
    fig, ax = plt.subplots(figsize=(10, 6))
    corr_matrix = df[['employeestatus', 'performance_score', 'engagement_score', 'satisfaction_score', 'work-life_balance_score', 'training_cost', 'age', 'employment_duration']].corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)
    st.pyplot(fig)

def train_model(df, model_option, n_estimators, max_depth, C_value=None, solver_option=None, learning_rate=None):
    """Train a machine learning model to predict employee attrition."""
    features = ['age', 'engagement_score', 'satisfaction_score', 'work-life_balance_score', 'performance_score', 'current_employee_rating', 'employment_duration']
    target = 'employeestatus'

    # Extract feature matrix X and target vector y
    X = df[features]
    y = df['LeftCompany']

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

    # Handle class imbalance using SMOTE
    smote = SMOTE(random_state=42)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

    # Initialize and train the model based on the selected option
    if model_option == "Random Forest":
        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
    elif model_option == "Logistic Regression":
        from sklearn.linear_model import LogisticRegression
        model = LogisticRegression(C=C_value, solver=solver_option, random_state=42)
    elif model_option == "XGBoost":
        from xgboost import XGBClassifier
        model = XGBClassifier(learning_rate=learning_rate, max_depth=max_depth, random_state=42)
    else:
        raise ValueError("Invalid model option")

    # Train the model
    model.fit(X_train_res, y_train_res)

    # Evaluate model performance
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    accuracy = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)

    # Save the trained model
    joblib.dump(model, 'best_model.pkl')

    return model, accuracy, roc_auc, precision, recall, f1, conf_matrix

def build_dashboard(df):
    # Inject custom CSS for the expander
    st.markdown(
        """
        <style>
        .streamlit-expanderHeader {
            color: white; /* Change the text color */
            background-color: #007BFF; /* Change the background color */
            padding: 5px; /* Optional: Add padding */
            border-radius: 5px; /* Optional: Rounded corners */
        }
        .streamlit-expander {
            background-color: #F8F9FA; /* Optional: Background for the expander body */
            border: 1px solid #007BFF; /* Optional: Add a border */
            border-radius: 5px; /* Optional: Rounded corners */
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("ðŸŒŸ HR Analytics Dashboard")
    st.sidebar.title("ðŸ”Ž Filters")
    st.sidebar.markdown("Filter the dataset to your needs.")

    # Sidebar filters
    with st.sidebar.expander("ðŸ¢ Select Department", expanded=False):
        selected_departments = st.multiselect(
            "Department",
            options=df['departmenttype'].unique(),
            default=df['departmenttype'].unique()
        )
        filtered_data = df[df['departmenttype'].isin(selected_departments)]

    with st.sidebar.expander("ðŸ‘¨â€ðŸ’¼ Select Employee Status", expanded=False):
        selected_employeestatus = st.multiselect(
            "Employee Status",
            options=df['EmployeeStatusLabel'].unique(),
            default=df['EmployeeStatusLabel'].unique()
        )
        filtered_data = filtered_data[filtered_data['EmployeeStatusLabel'].isin(selected_employeestatus)]

    with st.sidebar.expander("ðŸ§‘â€ðŸ’» Select Employee Type", expanded=False):
        selected_employeetypes = st.multiselect(
            "Employee Type",
            options=df['employeetype'].unique(),
            default=df['employeetype'].unique()
        )
        filtered_data = filtered_data[filtered_data['employeetype'].isin(selected_employeetypes)]

    with st.sidebar.expander("ðŸ’° Select Payzone", expanded=False):
        selected_payzones = st.multiselect(
            "Payzone",
            options=df['payzone'].unique(),
            default=df['payzone'].unique()
        )
        filtered_data = filtered_data[filtered_data['payzone'].isin(selected_payzones)]

    with st.sidebar.expander("âš ï¸ Select Termination Type", expanded=False):
        selected_terminationtypes = st.multiselect(
            "Termination Type",
            options=df['terminationtype'].unique(),
            default=df['terminationtype'].unique()
        )
        filtered_data = filtered_data[filtered_data['terminationtype'].isin(selected_terminationtypes)]

    with st.sidebar.expander("ðŸ“ Select Location", expanded=False):
        selected_locations = st.multiselect(
            "Location",
            options=df['state'].unique(),
            default=df['state'].unique()
        )
        filtered_data = filtered_data[filtered_data['state'].isin(selected_locations)]

    with st.sidebar.expander("ðŸ”¢ Filter by Age", expanded=False):
        age_range = st.slider(
            "Select Age Range",
            int(df['age'].min()),
            int(df['age'].max()),
            (24, 89)
        )
        filtered_data = filtered_data[(filtered_data['age'] >= age_range[0]) & (filtered_data['age'] <= age_range[1])]

    with st.sidebar.expander("ðŸ“ˆ Filter by Performance Score", expanded=False):
        performance_range = st.slider(
            "Select Performance Score Range",
            int(df['performance_score'].min()),
            int(df['performance_score'].max()),
            (1, 5)
        )
        filtered_data = filtered_data[(filtered_data['performance_score'] >= performance_range[0]) & (filtered_data['performance_score'] <= performance_range[1])]

    # Tabs for categories
    tabs = st.tabs(["ðŸ¢ Overview", "ðŸ“Š Department Insights", "ðŸ˜Š Engagement Analysis", "ðŸšª Attrition Analysis", "ðŸ”® Predictive Modeling", "ðŸ“¥ Download Data", "ðŸ“ User Feedback"])

    # Overview Tab with Key Metrics
    with tabs[0]:
        st.subheader("Dataset Overview ðŸ“‚")
        st.write(filtered_data.describe())
        st.dataframe(filtered_data.head(10))

        # Key Metrics
        st.subheader("Key Metrics")

        total_employees = len(filtered_data)
        average_age = filtered_data['age'].mean()
        average_performance_score = filtered_data['performance_score'].mean()
        average_engagement_score = filtered_data['engagement_score'].mean()
        average_satisfaction_score = filtered_data['satisfaction_score'].mean()
        average_work_life_balance_score = filtered_data['work-life_balance_score'].mean()

        col1, col2, col3 = st.columns(3)
        col1.metric("Total Employees", total_employees)
        col2.metric("Avg Age", f"{average_age:.1f}")
        col3.metric("Avg Performance Score", f"{average_performance_score:.1f}")

        col4, col5, col6 = st.columns(3)
        col4.metric("Avg Engagement Score", f"{average_engagement_score:.1f}")
        col5.metric("Avg Satisfaction Score", f"{average_satisfaction_score:.1f}")
        col6.metric("Avg Work-Life Balance Score", f"{average_work_life_balance_score:.1f}")

        # Gender Distribution (Count Plot)
        st.subheader("Gender Distribution")
        fig, ax = plt.subplots()
        sns.countplot(x='gendercode', data=filtered_data, palette='Set2', ax=ax)
        st.pyplot(fig)

        # Age Distribution (Histogram with KDE)
        st.subheader("Age Distribution")
        fig, ax = plt.subplots()
        sns.histplot(filtered_data['age'], kde=True, bins=20, color='purple', ax=ax)
        st.pyplot(fig)

        # Employee Status Distribution (Pie Chart)
        status_reverse_mapping = {1: 'Active', 2: 'Future Start', 3: 'Voluntarily Terminated', 4: 'Leave of Absence', 5: 'Terminated for Cause'}
        filtered_data['EmployeeStatusLabel'] = filtered_data['employeestatus'].map(status_reverse_mapping)
        st.subheader("Employee Status Distribution")
        status_counts = filtered_data['EmployeeStatusLabel'].value_counts()
        fig, ax = plt.subplots()
        ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', colors=sns.color_palette('Set1', len(status_counts)))
        ax.set_title("Employee Status")
        st.pyplot(fig)

        # Department Type Distribution (Count Plot)
        st.subheader("Department Type Distribution")
        fig, ax = plt.subplots()
        sns.countplot(x='departmenttype', data=filtered_data, palette='coolwarm', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Employee Type Distribution (Count Plot)
        st.subheader("Employee Type Distribution")
        fig, ax = plt.subplots()
        sns.countplot(x='employeetype', data=filtered_data, palette='Set3', ax=ax)
        st.pyplot(fig)

    # Department Insights Tab with Key Metrics
    with tabs[1]:
        st.subheader("Departmental Insights ðŸ¢")
        dept_counts = filtered_data['departmenttype'].value_counts()
        st.bar_chart(dept_counts)

        # Performance Score by Department
        st.subheader("Performance Score Distribution by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='performance_score', data=filtered_data, palette='coolwarm', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Engagement Score by Department
        st.subheader("Engagement Score by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='engagement_score', data=filtered_data, palette='Blues', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Satisfaction Score by Department
        st.subheader("Satisfaction Score by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='satisfaction_score', data=filtered_data, palette='YlGnBu', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Work-life Balance Score by Department
        st.subheader("Work-life Balance Score by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='work-life_balance_score', data=filtered_data, palette='viridis', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Training Outcome by Department
        st.subheader("Training Outcome by Department")
        fig, ax = plt.subplots()
        sns.countplot(x='departmenttype', hue='training_outcome', data=filtered_data, palette='Pastel1', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Training Cost by Department
        st.subheader("Training Cost by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='training_cost', data=filtered_data, palette='coolwarm', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Employment Duration by Department
        st.subheader("Employment Duration by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='employment_duration', data=filtered_data, palette='GnBu', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

    # Engagement Analysis Tab
    with tabs[2]:
        st.subheader("Employee Engagement Analysis ðŸ˜Š")

        # Engagement Score Distribution
        st.subheader("Engagement Score Distribution")
        fig, ax = plt.subplots()
        sns.histplot(filtered_data['engagement_score'], kde=True, color='blue', ax=ax)
        st.pyplot(fig)

        # Satisfaction Score Analysis
        st.subheader("Satisfaction Score Analysis")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='satisfaction_score', data=filtered_data, palette='magma', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Work-Life Balance Score Analysis
        st.subheader("Work-Life Balance Score Analysis")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='work-life_balance_score', data=filtered_data, palette='magma', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

    # Attrition Analysis Tab
    with tabs[3]:
        st.subheader("Attrition Analysis ðŸšª")

        # Attrition Status Breakdown
        st.subheader("Attrition Status Breakdown")
        fig, ax = plt.subplots()
        sns.countplot(x='LeftCompany', data=filtered_data, palette='Set1', ax=ax)
        ax.set_xticklabels(['Stayed', 'Left'], rotation=0)
        st.pyplot(fig)

        # Attrition by Age Group
        st.subheader("Attrition by Age Group")
        fig, ax = plt.subplots()
        sns.kdeplot(filtered_data[filtered_data['LeftCompany'] == 1]['age'], label='Left Company', color='red', shade=True, ax=ax)
        sns.kdeplot(filtered_data[filtered_data['LeftCompany'] == 0]['age'], label='Stayed', color='green', shade=True, ax=ax)
        plt.legend()
        st.pyplot(fig)

    # Predictive Modeling Tab
    with tabs[4]:
        st.subheader("Employee Attrition Prediction ðŸ”®")

        st.markdown("Enter employee details below to predict attrition likelihood.")

        # User input form for all features
        age = st.number_input("Age", min_value=18, max_value=89, value=30)
        engagement_score = st.slider("Engagement Score", min_value=0, max_value=5, value=3)
        satisfaction_score = st.slider("Satisfaction Score", min_value=0, max_value=5, value=3)
        work_life_balance_score = st.slider("Work-Life Balance Score", min_value=0, max_value=5, value=3)
        performance_score = st.slider("Performance Score", min_value=1, max_value=4, value=1)
        st.markdown("""
              **Performance Score Guide:**
              - 1: Fully meets expectations
              - 2: Exceeds expectations
              - 3: Need improvement
              - 4: Performance improvement plan (PIP)
          """)
        current_employee_rating = st.slider("Current Employee Rating", min_value=0, max_value=5, value=3)
        employment_duration = st.number_input("Employment Duration (in days)", min_value=0, max_value=10000, value=365)

        # Predict button
        if st.button("Predict Attrition"):
            model = joblib.load('best_model.pkl')

            # Ensure user input aligns with the expected features
            user_data = np.array([[age, engagement_score, satisfaction_score,
                                  work_life_balance_score, performance_score,
                                  current_employee_rating, employment_duration]])

            # Prediction and probabilities
            prediction = model.predict(user_data)[0]
            prediction_prob = model.predict_proba(user_data)[0]

            if prediction == 1:
                st.error(f"âš ï¸ The model predicts the employee is **likely to leave** with {prediction_prob[1]:.2%} probability.")
            else:
                st.success(f"âœ… The model predicts the employee is **likely to stay** with {prediction_prob[0]:.2%} probability.")

    # Download Data Tab
    with tabs[5]:
        st.subheader("Download Filtered Data ðŸ“¥")
        st.write("Download the current filtered data as an Excel file.")
        if st.button("Download Excel"):
            filtered_data.to_excel("filtered_data.xlsx", index=False)
            st.success("File saved as `filtered_data.xlsx`.")

    # User Feedback Tab
    with tabs[6]:
        st.subheader("User Feedback ðŸ“")
        feedback = st.text_area("Please provide your feedback here:")
        if st.button("Submit Feedback"):
            st.success("Thank you for your feedback!")


# Streamlit App
st.title("ðŸ“ŠðŸ‘©ðŸ»â€ðŸ’» Data-X Corporation HR Analytics Dashboard")

# Sidebar for Data Upload
st.sidebar.header("ðŸ—‚ï¸ Upload Your Data")
uploaded_employee = st.sidebar.file_uploader("ðŸ‘¨â€ðŸ’¼ Upload Employee Data CSV", type="csv")
uploaded_engagement = st.sidebar.file_uploader("ðŸ¤ Upload Engagement Data CSV", type="csv")
uploaded_training = st.sidebar.file_uploader("ðŸ‘©ðŸ»â€ðŸ« Upload Training Data CSV", type="csv")

if uploaded_employee and uploaded_engagement and uploaded_training:
    files = {
        "employee_data": uploaded_employee,
        "engagement_data": uploaded_engagement,
        "training_data": uploaded_training,
    }

    raw_data = load_data(files)

    if raw_data is not None:
        st.write("### ðŸ’¾ Raw Data Preview")
        st.dataframe(raw_data.head())

        # Preprocess the data
        df_cleaned = preprocess_data(raw_data)
        st.write("### ðŸ—ƒï¸ Cleaned Data")
        st.dataframe(df_cleaned.head())

        # Tabs for EDA, Model Training, and Dashboard
        tab1, tab2, tab3 = st.tabs(["ðŸ“Š EDA", "ðŸ› ï¸ Model Training", "ðŸ“ˆ Dashboard"])

        # Exploratory Data Analysis
        with tab1:
            st.header("ðŸ“Š Exploratory Data Analysis")
            perform_eda(df_cleaned)

        # Model Training
        with tab2:
            st.header("ðŸ› ï¸ Model Training")

            st.subheader("Model Selection")
            model_option = st.selectbox("Choose a model for training", ["Random Forest", "Logistic Regression", "XGBoost"])

            st.write("### Model Hyperparameters")
            if model_option == "Random Forest":
                n_estimators = st.slider("Number of Estimators", 50, 200, 100)
                max_depth = st.slider("Max Depth", 5, 20, 10)
                # Set defaults for other parameters
                C_value = None
                solver_option = None
                learning_rate = None
            elif model_option == "Logistic Regression":
                C_value = st.slider("C (Inverse Regularization)", 0.01, 10.0, 1.0)
                solver_option = st.selectbox("Solver", ["lbfgs", "liblinear"])
                # Set defaults for other parameters
                n_estimators = None
                max_depth = None
                learning_rate = None
            elif model_option == "XGBoost":
                learning_rate = st.slider("Learning Rate", 0.01, 0.3, 0.1)
                max_depth = st.slider("Max Depth", 3, 10, 6)
                # Set defaults for other parameters
                n_estimators = None
                C_value = None
                solver_option = None

            # Add button to train model
            if st.button("Train Model"):
                with st.spinner('Training model...'):
                    trained_model, accuracy, roc_auc, precision, recall, f1, conf_matrix = train_model(
                        df_cleaned,
                        model_option,
                        n_estimators,
                        max_depth,
                        C_value,
                        solver_option,
                        learning_rate
                    )
                    st.success("Model training completed!")

                    st.write("### Model Performance")
                    st.write(f"Accuracy: {accuracy}")
                    st.write(f"ROC AUC: {roc_auc}")
                    st.write(f"Precision: {precision}")
                    st.write(f"Recall: {recall}")
                    st.write(f"F1 Score: {f1}")

                    st.write("### Confusion Matrix")
                    st.write(conf_matrix)

        # Dashboard
        with tab3:
            st.header("ðŸ“ˆ Interactive Dashboard")
            build_dashboard(df_cleaned)
else:
    st.info("Please upload all required datasets to proceed.")