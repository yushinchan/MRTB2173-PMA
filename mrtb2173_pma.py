# -*- coding: utf-8 -*-
"""MRTB2173 PMA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ImksJ-7C2Ox_koP5z6mYLxMWekU1vGEp
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from imblearn.over_sampling import SMOTE
import joblib
import os

# # ----------------------------------------------------------------------------
# # Load datasets
# !pip install kaggle
# from google.colab import files
# files.upload()  # Upload kaggle.json file here
# !mkdir ~/.kaggle
# !cp kaggle.json ~/.kaggle/
# !chmod 600 ~/.kaggle/kaggle.json
# !kaggle datasets download -d ravindrasinghrana/employeedataset --unzip
# # ----------------------------------------------------------------------------

# Sprint 1: Data Collection & Cleaning
def load_and_clean_data():
    print("Loading and cleaning data...")

    from google.colab import drive
    drive.mount('/content/drive')

    # Read CSV files into pandas DataFrames
    employee_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/employee/employee_data.csv')
    engagement_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/employee/employee_engagement_survey_data.csv')
    training_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset/employee/training_and_development_data.csv')

    # Merge datasets (employee_data + engagement_data + training_data)
    df = employee_data.merge(engagement_data, left_on='EmpID', right_on='Employee ID', how='left')
    df = df.merge(training_data, left_on='EmpID', right_on='Employee ID', how='left')

    # Standardize column names
    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')

    # Handle missing values for numeric columns by filling with median
    numeric_cols = ['engagement_score', 'satisfaction_score', 'work_life_balance_score', 'training_cost']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = df[col].fillna(df[col].median())

    # Drop irrelevant or unnamed columns
    df.drop(columns=['unnamed:_0'], errors='ignore', inplace=True)

    # Convert date columns to datetime
    date_cols = ['startdate', 'exitdate']
    for col in date_cols:
        df[col] = pd.to_datetime(df[col], format='%d-%b-%y', errors='coerce')

    # Handle the dob column separately for dd/mm/yyyy format
    df['dob'] = df['dob'].str.replace(r'[^\d]', '', regex=True)
    df['dob'] = pd.to_datetime(df['dob'], format='%d%m%Y', errors='coerce')

    # Calculate Age and Employment Duration
    df['age'] = 2025 - df['dob'].dt.year
    # Fill missing exit dates with today's date for active employees
    df['exitdate'].fillna(pd.Timestamp.today(), inplace=True)
    df['employment_duration'] = (df['exitdate'] - df['startdate']).dt.days

    # Standardize and encode categorical columns
    label_encoder = LabelEncoder()
    status_mapping = {'Active': 1, 'Future Start': 2, 'Voluntarily Terminated': 3, 'Leave of Absence': 4, 'Terminated for Cause': 5}
    df['employeestatus'] = df['employeestatus'].map(status_mapping)
    performance_mapping = {'Fully Meets': 1, 'Exceeds': 2, 'Needs Improvement': 3, 'PIP': 4}
    df['performance_score'] = df['performance_score'].map(performance_mapping)

    # Drop unique columns
    df = df.drop(columns=['firstname', 'lastname', 'startdate', 'exitdate', 'title', 'supervisor', 'ademail', 'businessunit', 'terminationdescription', 'dob', 'jobfunctiondescription',
                          'locationcode', 'employee_id_x', 'survey_date', 'employee_id_y', 'training_date', 'location', 'trainer'])

    # General overview
    print(df.info())
    print(df.describe())

    return df

# Call the cleaning function
df_cleaned = load_and_clean_data()

# Preview the cleaned data and number of rows & columns
print(df_cleaned.head())
n_rows, n_columns = df_cleaned.shape
print("Total number of rows =", n_rows)
print("Total number of columns =", n_columns)
print(df_cleaned.columns)

# Sprint 2: EDA
def perform_eda(df):
    print("Performing exploratory data analysis...")

    # General overview
    print(df.info())
    print(df.describe())

    # Visualizing key trends for categorical variables
    plt.figure(figsize=(10, 6))
    sns.countplot(x='departmenttype', data=df, hue='payzone', palette='Set2')
    plt.title("Department Distribution by Payzone")
    plt.xticks(rotation=45)
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.countplot(x='gendercode', data=df, hue='payzone', palette='coolwarm')
    plt.title("Gender Distribution by Payzone")
    plt.show()

    status_reverse_mapping = {1: 'Active', 2: 'Future Start', 3: 'Voluntarily Terminated', 4: 'Leave of Absence', 5: 'Terminated for Cause'}
    df['EmployeeStatusLabel'] = df['employeestatus'].map(status_reverse_mapping)
    plt.figure(figsize=(10, 6))
    sns.countplot(x='EmployeeStatusLabel', data=df, hue='payzone', palette='Set2')
    plt.title("Employee Status Distribution by Payzone")
    plt.xticks(rotation=45)
    plt.show()

    plt.figure(figsize=(8, 8))
    employee_type_pie = df.groupby(['employeetype', 'payzone']).size().unstack().fillna(0)
    employee_type_pie.plot.pie(subplots=True, autopct='%1.1f%%', figsize=(10, 6), legend=True, wedgeprops=dict(width=0.4))
    plt.title("Employee Type Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(8, 8))
    marital_status_pie = df.groupby(['maritaldesc', 'payzone']).size().unstack().fillna(0)
    marital_status_pie.plot.pie(subplots=True, autopct='%1.1f%%', figsize=(10, 6), legend=True, wedgeprops=dict(width=0.4))
    plt.title("Marital Status Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(8, 8))
    race_desc_pie = df.groupby(['racedesc', 'payzone']).size().unstack().fillna(0)
    race_desc_pie.plot.pie(subplots=True, autopct='%1.1f%%', figsize=(10, 6), legend=True, wedgeprops=dict(width=0.4))
    plt.title("Race Description Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(8, 8))
    training_outcome_pie = df.groupby(['training_outcome', 'payzone']).size().unstack().fillna(0)
    training_outcome_pie.plot.pie(subplots=True, autopct='%1.1f%%', figsize=(10, 6), legend=True, wedgeprops=dict(width=0.4))
    plt.title("Training Outcome Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(8, 8))
    termination_type_pie = df.groupby(['terminationtype', 'payzone']).size().unstack().fillna(0)
    termination_type_pie.plot.pie(subplots=True, autopct='%1.1f%%', figsize=(10, 6), legend=True, wedgeprops=dict(width=0.4))
    plt.title("Termination Type Distribution by Payzone")
    plt.show()

    # Visualizing continuous variables distribution
    performance_reverse_mapping = {1: 'Fully Meets', 2: 'Exceeds', 3: 'Needs Improvement', 4: 'PIP'}
    df['PerformanceScoreLabel'] = df['performance_score'].map(performance_reverse_mapping)
    plt.figure(figsize=(10, 6))
    sns.histplot(df, x='PerformanceScoreLabel', hue='payzone', kde=True, palette='Set2')
    plt.title("Performance Score Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.histplot(df, x='engagement_score', hue='payzone', kde=True, palette='Set2')
    plt.title("Engagement Score Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.histplot(df, x='satisfaction_score', hue='payzone', kde=True, palette='Set2')
    plt.title("Satisfaction Score Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.histplot(df, x='work-life_balance_score', hue='payzone', kde=True, palette='Set2')
    plt.title("Work-Life Balance Score Distribution by Payzone")
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.histplot(df, x='training_cost', hue='payzone', kde=True, palette='Set2')
    plt.title("Training Cost Distribution by Payzone")
    plt.show()

    # Heatmap of correlation between continuous variables
    plt.figure(figsize=(10, 6))
    corr_matrix = df[['employeestatus', 'performance_score', 'current_employee_rating', 'engagement_score', 'satisfaction_score', 'work-life_balance_score', 'training_cost', 'age', 'employment_duration']].corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
    plt.title("Correlation Heatmap for Continuous Variables")
    plt.show()

    # Skewness and Kurtosis
    print("Skewness:")
    # Select only numeric columns for skewness calculation
    numeric_df = df.select_dtypes(include=np.number)
    print(numeric_df.skew())
    print("\nKurtosis:")
    print(numeric_df.kurtosis())

# Call the eda function
perform_eda(df_cleaned)

# Sprint 3: Build and Compare Models
def build_and_compare_models(df):
    print("Building and comparing models...")

    # Create the target variable 'LeftCompany' based on 'employeestatus'
    # '1' indicates the employee left the company, '0' means the employee is still employed
    df['LeftCompany'] = df['employeestatus'].apply(lambda x: 1 if x in [3, 4, 5] else 0)

    # Features: Select relevant columns for predicting employee turnover
    features = ['age', 'engagement_score', 'satisfaction_score', 'work-life_balance_score', 'performance_score', 'current_employee_rating', 'employment_duration']
    target = 'LeftCompany'

    # Extracting feature matrix X and target vector y
    X = df[features]
    y = df[target]

    # Splitting data into training and testing sets (70% training, 30% testing)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

    # Handling class imbalance with SMOTE
    smote = SMOTE(random_state=42)
    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

    # Initializing the models to be compared
    models = {
        'Logistic Regression': LogisticRegression(max_iter=500, class_weight='balanced', random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),
        'Gradient Boosting': GradientBoostingClassifier(random_state=42)
    }

    # Training and evaluating each model
    best_model = None
    best_roc_auc = 0
    for name, model in models.items():
        model.fit(X_train_smote, y_train_smote)
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

        # Evaluate model performance
        accuracy = accuracy_score(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None
        print(f"--- {name} ---")
        print(f"Accuracy: {accuracy:.2f}")
        if roc_auc is not None:
            print(f"ROC-AUC: {roc_auc:.2f}")
        print(classification_report(y_test, y_pred))
        print("\n")

        # Keep track of the best model
        if roc_auc and roc_auc > best_roc_auc:
            best_roc_auc = roc_auc
            best_model = (name, model)

    # Save the best model
    if best_model:
        model_name, model_instance = best_model
        try:
            joblib.dump(model_instance, f'best_model_{model_name}.pkl')
            print(f"Best model saved: {model_name}")
        except Exception as e:
            print(f"Error saving the model: {e}")
    else:
        print("No model selected as the best.")

# Call the build models function
build_and_compare_models(df_cleaned)

# Sprint 4: Dashboard
def build_dashboard(df):
    st.title("ðŸŒŸ HR Analytics Dashboard")
    st.sidebar.title("ðŸ”Ž Filters")
    st.sidebar.markdown("Filter the dataset to your needs.")
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
   # Sidebar filters
    selected_department = st.sidebar.selectbox("ðŸ¢ Select Department", options=df['departmenttype'].unique())
    filtered_data = df[df['departmenttype'] == selected_department]

    selected_employeestatus = st.sidebar.selectbox("ðŸ‘¨â€ðŸ’¼ Select Employee Status", options=df['employeestatus'].unique())
    filtered_data = filtered_data[filtered_data['employeestatus'] == selected_employeestatus]

    selected_employeetype = st.sidebar.selectbox("ðŸ§‘â€ðŸ’» Select Employee Type", options=df['employeetype'].unique())
    filtered_data = filtered_data[filtered_data['employeetype'] == selected_employeetype]

    selected_payzone = st.sidebar.selectbox("ðŸ’° Select Payzone", options=df['payzone'].unique())
    filtered_data = filtered_data[filtered_data['payzone'] == selected_payzone]

    selected_terminationtype = st.sidebar.selectbox("âš ï¸ Select Termination Type", options=df['terminationtype'].unique())
    filtered_data = filtered_data[filtered_data['terminationtype'] == selected_terminationtype]

    selected_location = st.sidebar.selectbox("ðŸ“ Select Location", options=df['state'].unique())
    filtered_data = filtered_data[filtered_data['state'] == selected_location]

    selected_maritalstatus = st.sidebar.selectbox("ðŸ’ Select Marital Status", options=df['maritaldesc'].unique())
    filtered_data = filtered_data[filtered_data['maritaldesc'] == selected_maritalstatus]

    selected_race = st.sidebar.selectbox("ðŸŒŽ Select Race", options=df['racedesc'].unique())
    filtered_data = filtered_data[filtered_data['racedesc'] == selected_race]

    st.sidebar.markdown("### ðŸ”¢ Filter by Age")
    age_range = st.sidebar.slider("Select Age Range", int(df['age'].min()), int(df['age'].max()), (25, 45))
    filtered_data = filtered_data[(filtered_data['age'] >= age_range[0]) & (filtered_data['age'] <= age_range[1])]

    st.sidebar.markdown("### ðŸ“ˆ Filter by Performance Score")
    performance_range = st.sidebar.slider("Select Performance Score Range", int(df['performance_score'].min()), int(df['performance_score'].max()), (60, 100))
    filtered_data = filtered_data[(filtered_data['performance_score'] >= performance_range[0]) & (filtered_data['performance_score'] <= performance_range[1])]
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # Tabs for categories
    tabs = st.tabs(["ðŸ¢ Overview", "ðŸ“Š Department Insights", "ðŸ˜Š Engagement Analysis", "ðŸšª Attrition Analysis", "ðŸ”® Predictive Modeling", "ðŸ“¥ Download Data", "ðŸ“ User Feedback"])
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # Overview Tab with Key Metrics
    with tabs[0]:
        st.subheader("Dataset Overview ðŸ“‚")
        st.write(filtered_data.describe())
        st.dataframe(filtered_data.head(10))

        # Key Metrics
        st.markdown("### Key Metrics")
        st.write(f"**Total Employees:** {len(filtered_data)}")
        st.write(f"**Avg Age:** {filtered_data['age'].mean():.1f}")
        st.write(f"**Avg Performance Score:** {filtered_data['performance_score'].mean():.1f}")
        st.write(f"**Avg Engagement Score:** {filtered_data['engagement_score'].mean():.1f}")
        st.write(f"**Avg Satisfaction Score:** {filtered_data['satisfaction_score'].mean():.1f}")
        st.write(f"**Avg Work-Life Balance Score:** {filtered_data['work-life_balance_score'].mean():.1f}")

        # Gender Distribution (Count Plot)
        st.subheader("Gender Distribution")
        fig, ax = plt.subplots()
        sns.countplot(x='gendercode', data=filtered_data, palette='Set2', ax=ax)
        st.pyplot(fig)

        # Age Distribution (Histogram with KDE)
        st.subheader("Age Distribution")
        fig, ax = plt.subplots()
        sns.histplot(filtered_data['age'], kde=True, bins=20, color='purple', ax=ax)
        st.pyplot(fig)

        # Employee Status Distribution (Pie Chart)
        st.subheader("Employee Status Distribution")
        status_counts = filtered_data['employeestatus'].value_counts()
        fig, ax = plt.subplots()
        ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', colors=sns.color_palette('Set1', len(status_counts)))
        ax.set_title("Employee Status")
        st.pyplot(fig)

        # Performance Score Distribution (Box Plot)
        st.subheader("Performance Score Distribution")
        fig, ax = plt.subplots()
        sns.boxplot(x='performance_score', data=filtered_data, palette='coolwarm', ax=ax)
        st.pyplot(fig)

        # Department Type Distribution (Count Plot)
        st.subheader("Department Type Distribution")
        fig, ax = plt.subplots()
        sns.countplot(x='departmenttype', data=filtered_data, palette='coolwarm', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Termination Type Distribution (Bar Plot)
        st.subheader("Termination Type Distribution")
        fig, ax = plt.subplots()
        sns.barplot(x='terminationtype', y='empid', data=filtered_data, estimator='count', palette='magma', ax=ax)
        ax.set_ylabel("Employee Count")
        st.pyplot(fig)

        # Employee Type Distribution (Count Plot)
        st.subheader("Employee Type Distribution")
        fig, ax = plt.subplots()
        sns.countplot(x='employeetype', data=filtered_data, palette='Set3', ax=ax)
        st.pyplot(fig)
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # Department Insights Tab with Key Metrics
    with tabs[1]:
        st.subheader("Departmental Insights ðŸ¢")
        dept_counts = filtered_data['departmenttype'].value_counts()
        st.bar_chart(dept_counts)

        # Performance Score by Department
        st.subheader("Performance Score Distribution by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='performance_score', data=filtered_data, palette='coolwarm', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Engagement Score by Department
        st.subheader("Engagement Score by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='engagement_score', data=filtered_data, palette='Blues', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Satisfaction Score by Department
        st.subheader("Satisfaction Score by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='satisfaction_score', data=filtered_data, palette='YlGnBu', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Work-life Balance Score by Department
        st.subheader("Work-life Balance Score by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='work-life_balance_score', data=filtered_data, palette='viridis', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Training Outcome by Department
        st.subheader("Training Outcome by Department")
        fig, ax = plt.subplots()
        sns.countplot(x='departmenttype', hue='training_outcome', data=filtered_data, palette='Pastel1', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Training Cost by Department
        st.subheader("Training Cost by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='training_cost', data=filtered_data, palette='coolwarm', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Employment Duration by Department
        st.subheader("Employment Duration by Department")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='employment_duration', data=filtered_data, palette='GnBu', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # Engagement Analysis Tab
    with tabs[2]:
        st.subheader("Employee Engagement Analysis ðŸ˜Š")

        # Engagement Score Distribution
        st.subheader("Engagement Score Distribution")
        fig, ax = plt.subplots()
        sns.histplot(filtered_data['engagement_score'], kde=True, color='blue', ax=ax)
        st.pyplot(fig)

        # Satisfaction Score Analysis
        st.subheader("Satisfaction Score Analysis")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='satisfaction_score', data=filtered_data, palette='magma', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        # Work-Life Balance Score Analysis
        st.subheader("Work-Life Balance Score Analysis")
        fig, ax = plt.subplots()
        sns.boxplot(x='departmenttype', y='work-life_balance_score', data=filtered_data, palette='magma', ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # Attrition Analysis Tab
    with tabs[3]:
        st.subheader("Attrition Analysis ðŸšª")

        # Attrition Status Breakdown
        st.subheader("Attrition Status Breakdown")
        fig, ax = plt.subplots()
        sns.countplot(x='LeftCompany', data=filtered_data, palette='Set1', ax=ax)
        ax.set_xticklabels(['Stayed', 'Left'], rotation=0)
        st.pyplot(fig)

        # Attrition by Age Group
        st.subheader("Attrition by Age Group")
        fig, ax = plt.subplots()
        sns.kdeplot(filtered_data[filtered_data['LeftCompany'] == 1]['age'], label='Left Company', color='red', shade=True, ax=ax)
        sns.kdeplot(filtered_data[filtered_data['LeftCompany'] == 0]['age'], label='Stayed', color='green', shade=True, ax=ax)
        plt.legend()
        st.pyplot(fig)
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # Predictive Modeling Tab
    with tabs[4]:
        st.subheader("Employee Attrition Prediction ðŸ”®")

        st.markdown("Enter employee details below to predict attrition likelihood.")

        # User input form
        age = st.number_input("Age", min_value=18, max_value=65, value=30)
        engagement_score = st.slider("Engagement Score", min_value=0, max_value=100, value=75)
        satisfaction_score = st.slider("Satisfaction Score", min_value=0, max_value=100, value=80)

        # Predict button
        if st.button("Predict Attrition"):
            model = joblib.load('best_model.pkl')
            user_data = np.array([[age, engagement_score, satisfaction_score]])
            prediction = model.predict(user_data)[0]
            prediction_prob = model.predict_proba(user_data)[0]

            if prediction == 1:
                st.error(f"âš ï¸ The model predicts the employee is **likely to leave** with {prediction_prob[1]:.2%} probability.")
            else:
                st.success(f"âœ… The model predicts the employee is **likely to stay** with {prediction_prob[0]:.2%} probability.")
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # Download Data Tab
    with tabs[5]:
        st.subheader("Download Filtered Data ðŸ“¥")
        st.write("Download the current filtered data as an Excel file.")
        download = st.button("Download Excel")

        if download:
            filtered_data.to_excel("filtered_data.xlsx", index=False)
            st.write("File saved as `filtered_data.xlsx`.")
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # User Feedback Tab
    with tabs[6]:
        st.subheader("User Feedback ðŸ“")
        feedback = st.text_area("Please provide your feedback here:")
        if st.button("Submit Feedback"):
            st.write("Thank you for your feedback!")

    st.sidebar.success("Enhanced HR Analytics Dashboard!")

# Call the build dashboard function
build_dashboard(df_cleaned)

# Sprint 5: Deployment
def deploy_dashboard():
    os.system("streamlit run hr_dashboard.py")